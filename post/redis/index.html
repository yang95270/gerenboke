<!doctype html>
<html lang="en-us">
  <head>
    <title>redis-面试题 // 春洋笔记</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.72.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="http://www.chunyangbiji.top/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="redis-面试题"/>
<meta name="twitter:description" content="1.缓存穿透  缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
 解决方案： 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
2.缓存雪崩  缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
 解决方案：  缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
 3.缓存击穿  对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
 解决方案：  我们的目标是：尽量少的线程构建缓存(甚至是一个) &#43; 数据一致性 &#43; 较少的潜在危险，下面会介绍四种方法来解决这个问题：
  1、使用互斥锁(mutex key): 这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了（如下图）
如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）。
下面是Tim yang博客的代码，是memcache的伪代码实现
    如果换成redis，就是：
   2、&ldquo;提前&quot;使用互斥锁(mutex key)：  在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：
   3、&ldquo;永远不过期&rdquo;：  ​	这里的“永远不过期”包含两层意思：
​	1、从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
​	2、从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
    从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
   4、资源保护：  之前在缓存雪崩那篇文章提到了netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。"/>

    <meta property="og:title" content="redis-面试题" />
<meta property="og:description" content="1.缓存穿透  缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。
 解决方案： 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
2.缓存雪崩  缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
 解决方案：  缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
 3.缓存击穿  对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
 解决方案：  我们的目标是：尽量少的线程构建缓存(甚至是一个) &#43; 数据一致性 &#43; 较少的潜在危险，下面会介绍四种方法来解决这个问题：
  1、使用互斥锁(mutex key): 这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了（如下图）
如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）。
下面是Tim yang博客的代码，是memcache的伪代码实现
    如果换成redis，就是：
   2、&ldquo;提前&quot;使用互斥锁(mutex key)：  在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：
   3、&ldquo;永远不过期&rdquo;：  ​	这里的“永远不过期”包含两层意思：
​	1、从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
​	2、从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
    从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
   4、资源保护：  之前在缓存雪崩那篇文章提到了netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.chunyangbiji.top/post/redis/" />



  </head>
  <body>
    <header class="app-header">
      <a href="http://www.chunyangbiji.top/"><img class="app-header-avatar" src="/avatar.jpg" alt="John Doe" /></a>
      <h1>春洋笔记</h1>
      <p>朝阳热心群众分享.</p>
      <div class="app-header-social">
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">redis-面试题</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jan 1, 0001
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          4 min read
        </div></div>
    </header>
    <div class="post-content">
      <h1 id="1缓存穿透">1.缓存穿透</h1>
<blockquote>
<p>缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。</p>
</blockquote>
<h3 id="解决方案">解决方案：</h3>
<p>有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
<h1 id="2缓存雪崩">2.缓存雪崩</h1>
<blockquote>
<p>缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。</p>
</blockquote>
<h3 id="解决方案-1">解决方案：</h3>
<blockquote>
<p>缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p>
</blockquote>
<h1 id="3缓存击穿">3.缓存击穿</h1>
<blockquote>
<p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
</blockquote>
<h3 id="解决方案-2">解决方案：</h3>
<blockquote>
<p>我们的目标是：尽量少的线程构建缓存(甚至是一个) + 数据一致性 + 较少的潜在危险，下面会介绍四种方法来解决这个问题：</p>
</blockquote>
<blockquote>
<p>1、使用互斥锁(mutex key): 这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了（如下图）</p>
<p>如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）。</p>
<p>下面是Tim yang博客的代码，是memcache的伪代码实现</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis01.png"/> 
</figure>

<p><img src="./imgs/redis01.png" alt=""></p>
<blockquote>
<p>如果换成redis，就是：</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis02.png"/> 
</figure>

<p><img src="./imgs/redis02.png" alt=""></p>
<h4 id="2提前使用互斥锁mutex-key">2、&ldquo;提前&quot;使用互斥锁(mutex key)：</h4>
<blockquote>
<p>在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis03.png"/> 
</figure>

<p><img src="./imgs/redis03.png" alt=""></p>
<h4 id="3永远不过期">3、&ldquo;永远不过期&rdquo;：</h4>
<blockquote>
<p>​	这里的“永远不过期”包含两层意思：</p>
<p>​	1、从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。</p>
<p>​	2、从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis04.png"/> 
</figure>

<p><img src="./imgs/redis04.png" alt=""></p>
<blockquote>
<p>从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis05.png"/> 
</figure>

<p><img src="./imgs/redis05.png" alt=""></p>
<h4 id="4资源保护">4、资源保护：</h4>
<blockquote>
<p>之前在缓存雪崩那篇文章提到了netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。</p>
</blockquote>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis06.png"/> 
</figure>

<p><img src="./imgs/redis06.png" alt=""></p>
<h5 id="34种方案对比">3、4种方案对比：</h5>
<blockquote>
<p>作为一个并发量较大的互联网应用，我们的目标有3个: 1、加快用户访问速度，提高用户体验。 2、降低后端负载，保证系统平稳。 3、保证数据“尽可能”及时更新(要不要完全一致，取决于业务，而不是技术。)</p>
<p>所以第二节中提到的四种方法，可以做如下比较，还是那就话：没有最好，只有最合适。</p>
</blockquote>
<h3 id="分析">分析</h3>
<h4 id="解决方案-3">解决方案</h4>
<h5 id="一简单分布式锁tim-yang">一、简单分布式锁(Tim yang)</h5>
<blockquote>
<p><strong>优点</strong></p>
<p>1、思路简单 2、保证一致性</p>
<p><strong>缺点</strong></p>
<p>1、代码复杂度增大 2、存在死锁的风险 3、存在线程池阻塞的风险</p>
</blockquote>
<h5 id="二加另外一个过期时间tim-yang">二、加另外一个过期时间(Tim yang)</h5>
<blockquote>
<p><strong>优点</strong></p>
<p>1、保证一致性</p>
<p><strong>缺点</strong></p>
<p>1、代码复杂度增大 2、存在死锁的风险 3、存在线程池阻塞的风险</p>
</blockquote>
<h5 id="三不过期本文">三、不过期(本文)</h5>
<blockquote>
<p><strong>优点</strong></p>
<p>1、异步构建缓存，不会阻塞线程池</p>
<p><strong>缺点</strong></p>
<p>1、不保证一致性。 2、代码复杂度增大(每个value都要维护一个timekey)。 3、占用一定的内存空间(每个value都要维护一个timekey)。</p>
</blockquote>
<h5 id="四不过期本文">四、不过期(本文)</h5>
<blockquote>
<p><strong>优点</strong></p>
<p>1、hystrix技术成熟，有效保证后端。 2、hystrix监控强大。</p>
<p><strong>缺点</strong></p>
<p>1、部分访问存在降级策略。</p>
</blockquote>
<h4 id="总结">总结</h4>
<blockquote>
<p>热点key + 过期时间 + 复杂的构建缓存过程 =&gt; mutex key问题 构建缓存一个线程做就可以了。 四种解决方案：没有最佳只有最合适。</p>
</blockquote>
<h1 id="4-什么是缓存并发竞争怎么解决">4. 什么是缓存并发竞争？怎么解决？</h1>
<blockquote>
<p>多个客户端写一个 key，如果顺序错了，数据就不对了。但是顺序我们无法控制。</p>
</blockquote>
<h3 id="解决方案-4">解决方案：</h3>
<blockquote>
<p>使用分布式锁，例如 zk，同时加入数据的时间戳。同一时刻，只有抢到锁的客户端才能写入，同时，写入时，比较当前数据的时间戳和缓存中数据的时间戳。</p>
</blockquote>
<h1 id="5什么是缓存和数据库双写不一致怎么解决">5.什么是缓存和数据库双写不一致？怎么解决？</h1>
<blockquote>
<p>连续写数据库和缓存，但是操作期间，出现并发了，数据不一致了。解决方案：</p>
</blockquote>
<h3 id="解决方案-5">解决方案：</h3>
<p>​	通常，更新缓存和数据库有以下几种顺序：</p>
<p>​		先更新数据库，再更新缓存。</p>
<p>​		先删缓存，再更新数据库。</p>
<p>​		先更新数据库，再删除缓存。</p>
<p>​	<strong>先更新数据库，再更新缓存。</strong></p>
<blockquote>
<p>这么做的问题是：当有 2 个请求同时更新数据，那么如果不使用分布式锁，将无法控制最后缓存的值到底是多少。也就是并发写的时候有问题。</p>
</blockquote>
<p><strong>先删缓存，再更新数据库。</strong></p>
<blockquote>
<p>这么做的问题：如果在删除缓存后，有客户端读数据，将可能读到旧数据，并有可能设置到缓存中，导致缓存中的数据一直是老数据。</p>
<p>有 2 种解决方案：</p>
<ul>
<li>使用“双删”，即删更删，最后一步的删除作为异步操作，就是防止有客户端读取的时候设置了旧值。</li>
<li>使用队列，当这个 key 不存在时，将其放入队列，串行执行，必须等到更新数据库完毕才能读取数据。</li>
</ul>
<p>总的来讲，比较麻烦。</p>
</blockquote>
<p><strong>先更新数据库，再删除缓存</strong></p>
<blockquote>
<p>这个实际是常用的方案，但是有很多人不知道，这里介绍一下，这个叫 Cache Aside Pattern，老外发明的。如果先更新数据库，再删除缓存，那么就会出现更新数据库之前有瞬间数据不是很及时。</p>
<p>同时，如果在更新之前，缓存刚好失效了，读客户端有可能读到旧值，然后在写客户端删除结束后再次设置了旧值，非常巧合的情况。</p>
<p>有 2 个前提条件：<strong>缓存在写之前的时候失效，同时，在写客户度删除操作结束后，放置旧数据 —— 也就是读比写慢。设置有的写操作还会锁表。</strong></p>
<p>所以，这个很难出现，但是如果出现了怎么办？使用双删！！！记录更新期间有没有客户端读数据库，如果有，在更新完数据库之后，执行延迟删除。</p>
<p>还有一种可能，如果执行更新数据库，准备执行删除缓存时，服务挂了，执行删除失败怎么办？？？</p>
<p>这就坑了！！！不过可以通过订阅数据库的 binlog 来删除。</p>
</blockquote>
<h1 id="6redis-的特点">6.Redis 的特点？</h1>
<blockquote>
<p>Redis 是由意大利人 Salvatore Sanfilippo（网名：antirez）开发的一款内存高速缓存数据库。Redis 全称为：
Remote Dictionary Server（远程数据服务），该软件使用 C 语言编写，典型的 NoSQL 数据库服务器，Redis 是一
个 key-value 存储系统，它支持丰富的数据类型，如：string、list、set、zset(sorted set)、hash。</p>
<p>Redis 本质上是一个 Key-Value 类型的内存数据库，很像 memcached，整个 数据库统统加载在内存当中进行
操作，定期通过异步操作把数据库数据 flush 到硬盘上进行保存。因为是纯内存操作，Redis 的性能非常出色，每秒可
以处理超过 10 万次读写操作，是已知性能最快的 Key-Value DB。
Redis 的出色之处不仅仅是性能，Redis 最大的魅力是支持保存多种数据结构，此外单 个 value 的最大限制是
1GB，不像 memcached 只能保存 1MB 的数据，另外 Redis 也可以对存入的 Key-Value 设置 expire 时间。
Redis 的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要
局限在较小数据量的高性能操作和运算上</p>
</blockquote>
<h1 id="7-为什么-redis-需要把所有数据放到内存中">7. 为什么 redis 需要把所有数据放到内存中？</h1>
<blockquote>
<p>Redis 为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以 redis 具有快速和
数据持久化的特征。如果不将数据放在内存中，磁盘 I/O 速度为严重影响 redis 的性能。在内存越来越便宜的今天，
redis 将会越来越受欢迎。如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。</p>
</blockquote>
<h1 id="8-redis-常见的性能问题都有哪些如何解决">8. Redis 常见的性能问题都有哪些？如何解决？</h1>
<p>（1）、Master 写内存快照，save 命令调度 rdbSave 函数，会阻塞主线程的工作，当快照比较大时对性能影响是
非常大的，会间断性暂停服务，所以 Master 最好不要写内存快照。
（2）、Master AOF 持久化，如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会
不断增大，AOF 文件过大会影响 Master 重启的恢复速度。Master 最好不要做任何持久化工作，包括内存快照和 AOF
日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。
（3）、Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服
务 load 过高，出现短暂服务暂停现象。
（4）、Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域
网内</p>
<h1 id="9redis-最适合的场景有哪些">9.Redis 最适合的场景有哪些？</h1>
<p>（1）、会话缓存（Session Cache）
（2）、全页缓存（FPC）
（3）、队列
（4）、排行榜/计数器
（5）、发布/订阅</p>
<h1 id="10memcache-与-redis-的区别都有哪些">10.Memcache 与 Redis 的区别都有哪些？</h1>
<p>（1）、存储方式不同，Memcache 是把数据全部存在内存中，数据不能超过内存的大小，断电后数据库会挂掉</p>
<p>Redis 有部分存在硬盘上，这样能保证数据的持久性。
（2）、数据支持的类型不同 memcahe 对数据类型支持相对简单，redis 有复杂的数据类型。
（3）、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis 直接自己
构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
（4）、支持的 value 大小不一样 redis 最大可以达到 1GB，而 memcache 只有 1MB。</p>
<h2 id="11redis-用过-redisnx-吗redis-有哪几种数据结构">11.Redis 用过 RedisNX 吗？Redis 有哪几种数据结构？</h2>
<p>反正我是不知道 redisnx 是什么，度娘也不清楚，如果面试中问道自己没有接触过或者没有听过的技术可以直接
大胆的告诉他，没有接触过，或者没有听过。
Redis 的数据结构有五种，分别是：
<strong>String——字符串</strong>
String 数据结构是简单的 key-value 类型，value 不仅可以是 String，也可以是数字（当数字类型用 Long 可以
表示的时候 encoding 就是整型，其他都存储在 sdshdr 当做字符串）。
<strong>Hash——字典</strong>
在 Memcached 中，我们经常将一些结构化的信息打包成 hashmap，在客户端序列化后存储为一个字符串的值
（一般是 JSON 格式），比如用户的昵称、年龄、性别、积分等。
<strong>List——列表</strong>
List 说白了就是链表（redis 使用双端链表实现的 List），相信学过数据结构知识的人都应该能理解其结构。
<strong>Set——集合</strong>
Set 就是一个集合，集合的概念就是一堆不重复值的组合。利用 Redis 提供的 Set 数据结构，可以存储一些集合
性的数据</p>
<p><strong>Sorted Set——有序集合</strong>
和 Sets 相比，Sorted Sets 是将 Set 中的元素增加了一个权重参数 score，使得集合中的元素能够按 score 进
行有序排列，</p>
<ol>
<li>带有权重的元素，比如一个游戏的用户得分排行榜
2.比较复杂的数据结构，一般用到的场景不算太多</li>
</ol>
<h1 id="12-redis-的优缺点">12. Redis 的优缺点</h1>
<h3 id="优点"><strong>优点：</strong></h3>
<p>​	a) 性能极高 – Redis 能支持超过 100K+ 每秒的读写频率。
b) 丰富的数据类型 – Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
c) 原子 – Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作全并后的原子性执行。
**attention 原子性定义：**例如，A 想要从自己的帐户中转 1000 块钱到 B 的帐户里。那个从 A 开始转帐，到转帐结
束的这一个过程，称之为一个事务。如果在 A 的帐户已经减去了 1000 块钱的时候，忽然发生了意外，比如停电什么
的，导致转帐事务意外终止了，而此时 B 的帐户里还没有增加 1000 块钱。那么，我们称这个操作失败了，要进行回
滚。回滚就是回到事务开始之前的状态，也就是回到 A 的帐户还没减 1000 块的状态，B 的帐户的原来的状态。此时
A 的帐户仍然有 3000 块，B 的帐户仍然有 2000 块。我们把这种要么一起成功（A 帐户成功减少 1000，同时 B 帐户
成功增加 1000），要么一起失败（A 帐户回到原来状态，B 帐户也回到原来状态）的操作叫原子性操作。如果把一个
事务可看作是一个程序,它要么完整的被执行,要么完全不执行，这种特性就叫原子性。
·d）丰富的特性 – Redis 还支持 publish/subscribe, 通知, key 过期等等特性。</p>
<h3 id="缺点"><strong>缺点：</strong></h3>
<p>​	a）. 由于是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小。虽然 redis 本身有 key 过</p>
<p>期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。
b). 如果进行完整重同步，由于需要生成 rdb 文件，并进行传输，会占用主机的 CPU，并会消耗现网的带宽。
不过 redis2.8 版本，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如，新上线的备机。
c). 修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，redis 不能
提供服务。</p>
<h1 id="13redis-的持久化">13.Redis 的持久化</h1>
<h3 id="rdb-持久化">RDB 持久化：</h3>
<p>该机制可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。</p>
<h3 id="aof-持久化">AOF 持久化：</h3>
<p>记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF 文件
中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行
重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小</p>
<h3 id="无持久化">无持久化：</h3>
<p>让数据只在服务器运行时存在</p>
<p>同时应用 AOF 和 RDB：当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据
集通常比 RDB 文件所保存的数据集更完整</p>
<h3 id="rdb-的优缺点">RDB 的优缺点：</h3>
<p>​	<strong>优点</strong>：RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常
适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，
也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适用于
灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据
中心，或者亚马逊 S3 中。RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一
个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</p>
<p>​	<strong>缺点</strong>：如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的
保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为 RDB 文件需要保存整个数据集的状态， 所以
它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停
机， 你就可能会丢失好几分钟的数据。每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来
进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客
户端；如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。</p>
<h3 id="aof-的优缺点">AOF 的优缺点:</h3>
<p>​	<strong>优点：</strong>
1、使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 fsync 策略，比如
无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种
配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线
程执行，所以主线程可以继续努力地处理命令请求）。AOF 文件是一个只进行追加操作的日志文件（append only
log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入
时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。
2、Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢
复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续
将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件
创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作</p>
<p>​	<strong>缺点：</strong>
对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB
一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间
（latency）。</p>
<p>​	AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复
成保存时的原样。 （举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加
了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在
AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 。</p>
<h1 id="14redis中是如何实现分布式锁的">14.Redis中是如何实现分布式锁的？</h1>
<p>你对Redis使用熟悉吗？Redis中是如何实现分布式锁的?</p>
<p>分布式锁常见的三种实现方式：</p>
<ol>
<li>数据库乐观锁；</li>
<li>基于Redis的分布式锁；</li>
<li>基于ZooKeeper的分布式锁。</li>
</ol>
<h3 id="要点">要点</h3>
<p>Redis要实现分布式锁，以下条件应该得到满足</p>
<p><strong>互斥性</strong></p>
<ul>
<li>在任意时刻，只有一个客户端能持有锁。</li>
</ul>
<p><strong>不能死锁</strong></p>
<ul>
<li>客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。</li>
</ul>
<p><strong>容错性</strong></p>
<ul>
<li>只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。</li>
</ul>
<h2 id="实现">实现</h2>
<p>可以直接通过 <code>set key value px milliseconds nx</code> 命令实现加锁， 通过Lua脚本实现解锁。</p>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis07.png"/> 
</figure>

<p><img src="./imgs/redis07.png" alt=""></p>
<h4 id="代码解释"><strong>代码解释</strong></h4>
<ul>
<li>set 命令要用 <code>set key value px milliseconds nx</code>，替代 <code>setnx + expire</code> 需要分两次执行命令的方式，保证了原子性，</li>
<li>value 要具有唯一性，可以使用<code>UUID.randomUUID().toString()</code>方法生成，用来标识这把锁是属于哪个请求加的，在解锁的时候就可以有依据；</li>
<li>释放锁时要验证 value 值，防止误解锁；</li>
<li>通过 Lua 脚本来避免 Check And Set 模型的并发问题，因为在释放锁的时候因为涉及到多个Redis操作 （利用了eval命令执行Lua脚本的原子性）；</li>
</ul>
<h4 id="加锁代码分析"><strong>加锁代码分析</strong></h4>
<p>首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，用来标识这把锁是属于哪个请求加的，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。</p>
<h4 id="解锁代码分析"><strong>解锁代码分析</strong></h4>
<p>将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。在执行的时候，首先会获取锁对应的value值，检查是否与requestId相等，如果相等则解锁（删除key）。</p>
<h4 id="存在的风险"><strong>存在的风险</strong></h4>
<p>如果存储锁对应key的那个节点挂了的话，就可能存在丢失锁的风险，导致出现多个客户端持有锁的情况，这样就不能实现资源的独享了。</p>
<ol>
<li>客户端A从master获取到锁</li>
<li>在master将锁同步到slave之前，master宕掉了（Redis的主从同步通常是异步的）。
主从切换，slave节点被晋级为master节点</li>
<li>客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。导致存在同一时刻存不止一个线程获取到锁的情况。</li>
</ol>
<h2 id="redlock算法出现">redlock算法出现</h2>
<p>这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：</p>
<ol>
<li>获取当前时间戳，单位是毫秒；</li>
<li>跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；</li>
<li>尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；</li>
<li>客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；</li>
<li>要是锁建立失败了，那么就依次之前建立过的锁删除；</li>
<li>只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。</li>
</ol>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis08.png"/> 
</figure>

<p><img src="./imgs/redis08.png" alt=""></p>
<h3 id="redisson实现">Redisson实现</h3>
<p>Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。</p>
<p>Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
<p><strong>Redisson 分布式重入锁用法</strong></p>
<p>Redisson 支持单点模式、主从模式、哨兵模式、集群模式，这里以单点模式为例：</p>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis09.png"/> 
</figure>

<p><img src="./imgs/redis09.png" alt=""></p>
<p>加锁流程图</p>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis10.jpg"/> 
</figure>

<p><img src="./imgs/redis10.jpg" alt=""></p>
<p>解锁流程图</p>
<figure>
    <img src="http://qcbkk8ti4.bkt.clouddn.com/redis11.jpg"/> 
</figure>

<p><img src="./imgs/redis11.jpg" alt=""></p>
<p>我们可以看到，RedissonLock是可重入的，并且考虑了失败重试，可以设置锁的最大等待时间， 在实现上也做了一些优化，减少了无效的锁申请，提升了资源的利用率。</p>
<p>需要特别注意的是，RedissonLock 同样没有解决 节点挂掉的时候，存在丢失锁的风险的问题。而现实情况是有一些场景无法容忍的，所以 Redisson 提供了实现了redlock算法的 RedissonRedLock，RedissonRedLock 真正解决了单点失败的问题，代价是需要额外的为 RedissonRedLock 搭建Redis环境。</p>
<p>所以，如果业务场景可以容忍这种小概率的错误，则推荐使用 RedissonLock， 如果无法容忍，则推荐使用 RedissonRedLock。</p>
<h1 id="15redis-的过期策略">15.Redis 的过期策略</h1>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
